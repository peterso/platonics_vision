#!/usr/bin/env python3
import os
from geometry_msgs.msg import PoseStamped
import rospy
from sensor_msgs.msg import Image
from platonics_vision.localizer_sift import Localizer
from platonics_vision.sift_template import SiftTemplate
from sensor_msgs.msg import CameraInfo
import numpy as np

from platonics_vision.srv import SiftRegistrationLocalizer, SiftRegistrationLocalizerResponse, MultiSiftRegistrationLocalizer, MultiSiftRegistrationLocalizerResponse
from platonics_vision.srv import SavingTemplate, SavingTemplateRequest, SavingTemplateResponse
import rospkg
import tf2_ros
import tf
import yaml

from cv_bridge import CvBridge

class LocalizationService():
    _templates_folder: str

    def __init__(self) -> None:
        rospy.init_node("localization_server")
        self._rate = rospy.Rate(5)

        rospack = rospkg.RosPack()
        self._templates_folder = rospack.get_path("platonics_dataset") + "/trajectories/"

        self._localizer = Localizer()
        self.bridge = CvBridge()
        self._publisher_counter = 0
        self._sift_template = SiftTemplate()

        self.establish_ros_connections()

    def get_transformation_matrix(self, source_frame='panda_link0', target_frame='camera_color_optical_frame'):
    
        # Get the transformation matrix
        try:
            transform = self._tf_buffer.lookup_transform(source_frame, target_frame, rospy.Time(0), rospy.Duration(1.0))
        except (tf2_ros.LookupException, tf2_ros.ConnectivityException, tf2_ros.ExtrapolationException):
            rospy.logerr("Transform not available")
            return None
        # Convert transform to a 4x4 matrix
        trans = transform.transform.translation
        rot = transform.transform.rotation
        return np.array([
            [1-2*(rot.y**2 + rot.z**2), 2*(rot.x*rot.y - rot.z*rot.w), 2*(rot.x*rot.z + rot.y*rot.w), trans.x],
            [2*(rot.x*rot.y + rot.z*rot.w), 1-2*(rot.x**2 + rot.z**2), 2*(rot.y*rot.z - rot.x*rot.w), trans.y],
            [2*(rot.x*rot.z - rot.y*rot.w), 2*(rot.y*rot.z + rot.x*rot.w), 1-2*(rot.x**2 + rot.y**2), trans.z],
            [0, 0, 0, 1]
        ])

    def handle_save_template_request(self, req: SavingTemplateRequest):

        #bash_script = f'rosrun platonics_vision record_template {req.template_name.data}'
        #print(bash_script)
        #os.system(bash_script)
        name_template = self._templates_folder + req.template_name.data
        print("Recording template name: ", name_template)
        self._sift_template.record(img=self._img, depth_img=self._depth_img, name=name_template, panda_link_tf=self.get_transformation_matrix())
        response = SavingTemplateResponse()
        response.success.data = True
        return response

    def establish_ros_connections(self):
        self.image_publisher = rospy.Publisher("/SIFT_localization", Image, queue_size=10)
        self._service = rospy.Service('sift_localization', SiftRegistrationLocalizer, self.handle_request)
        self._multi_service = rospy.Service('multi_sift_localization', MultiSiftRegistrationLocalizer, self.handle_multi_request)
        self._save_template_service = rospy.Service('saving_sift_template', SavingTemplate, self.handle_save_template_request)
        rospy.Subscriber("/camera/color/camera_info", CameraInfo, self.camera_info_callback)
        self.image_sub = rospy.Subscriber('/camera/color/image_raw', Image, self.image_callback)
        self.depth_image_sub = rospy.Subscriber('camera/depth/image_filtered', Image, self.depth_image_callback)
        self._tf_buffer = tf2_ros.Buffer()
        self._tf_listener = tf2_ros.TransformListener(self._tf_buffer)

    def image_callback(self, img: Image):
        self._img = img

    def depth_image_callback(self, img: Image):
        self._depth_img = img

    def camera_info_callback(self, msg: CameraInfo):
        self.cx_cy_array = np.array([[msg.K[2]], [msg.K[5]]])
        self._fx = msg.K[0]
        self._fy = msg.K[4]
        self._localizer.set_intrinsics(self._fx, self._fy, self.cx_cy_array[0], self.cx_cy_array[1])

    def handle_multi_request(self, req: MultiSiftRegistrationLocalizer):
        response = MultiSiftRegistrationLocalizerResponse()
        yaws = []
        for template_folder_name in req.template_folder_names:
            tf_matrix = self.compute_localization_in_m(template_folder_name)
            yaw = tf.transformations.euler_from_matrix(tf_matrix[0:4, 0:4])[2]
            rospy.loginfo(f"Angle for {template_folder_name} is {yaw}")
            yaws.append(abs(yaw))
        index = np.argmin(np.array(yaws))
        response.closest_template_name = req.template_folder_names[index]
        return response



    def compute_localization_in_m(self, template_folder_name: str):
        cv_image = self.bridge.imgmsg_to_cv2(self._img, "bgr8")
        template_file = self._templates_folder + template_folder_name + "/template/full_image.png"
        params_file = self._templates_folder + template_folder_name + "/template/params.yaml"
        params = yaml.load(open(params_file, 'r'), Loader=yaml.FullLoader)
        #self._localizer.set_cropping(params['crop'])
        self._localizer.set_box_depth(float(params['depth']) * 0.001)
        polygon_points = params['polygon']
        self._localizer.set_template_from_polygon_points(template_file, polygon_points)
        self._localizer.set_depth_template(self._templates_folder + template_folder_name + "/template/depth.npy")
        self._localizer.set_image(cv_image)
        self._localizer.set_template_tf(params['panda_link_tf'])
        depth_image = self.bridge.imgmsg_to_cv2(self._depth_img, desired_encoding="passthrough")
        self._localizer.set_depth_image(depth_image)
        try:
            self._localizer.detect_points()
        except Exception as e:
            print(e)
            print('Returning identity')
            return np.identity(4)
        tf_matrix = self._localizer.compute_full_tf_in_m(self.get_transformation_matrix())
        return tf_matrix
    
    def publish_annoted_image(self):
        ros_image = self.bridge.cv2_to_imgmsg(self._localizer.annoted_image(), "bgr8")
        self.image_publisher.publish(ros_image)


    def handle_request(self, req: SiftRegistrationLocalizer):
        tf_matrix = self.compute_localization_in_m(req.template_folder_name.data)
        
        position = tf_matrix[0:3, 3]
        quaternion = tf.transformations.quaternion_from_matrix(tf_matrix[0:4, 0:4])
        quaternion = quaternion/np.linalg.norm(quaternion)
        # Publish pose
        pose = PoseStamped()
        pose.pose.position.x = position[0]
        pose.pose.position.y = position[1]
        pose.pose.position.z = position[2]
        pose.pose.orientation.w = quaternion[3]
        pose.pose.orientation.x = quaternion[0]
        pose.pose.orientation.y = quaternion[1]
        pose.pose.orientation.z = quaternion[2]
        self.publish_annoted_image()
    
        return SiftRegistrationLocalizerResponse(pose)


    def run(self):
        while not rospy.is_shutdown():
            self._rate.sleep()
    
if __name__ == '__main__':
    simple_localizer_node = LocalizationService()
    try:
        simple_localizer_node.run()
    except rospy.ROSInterruptException:
        pass
